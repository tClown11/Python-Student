    网络数据采集程序：有时称为网络机器人（bots），是一种通过多种手段收集网络数据
的方式，不光是通过与API交互的方式。最通常的方法是写一个自动化程序向网络服务
器请求数据（通常是用HTML表单或其他网页文件），然后对数据进行解析，提取需要的
信息。
    为什么要做网络数据采集：可以完成传统搜索引擎不能做的事情。设计较好的网络爬虫
可以通过采集大量的网站数据，做出飞往波士顿航班价格随时间变化的图表，告诉你买机票
的最佳时间。显然，大量的应用场景都会需要这种几乎可以毫无阻碍地获取数据的手段：市
场预测、机器语言翻译，甚至医疗诊断，通过对新闻网站、文章以及健康论坛中的数据进行
采集和分析，也可以获得很多好处。

创建爬虫：
    通过网站域名获取HTML数据
    根据目标信息解析数据
    存储目标信息
    如果有必要，移动到另一个网页重复这个过程


    所有代码示例：https://github.com/REMitchell/python-scraping

初见网络爬虫

    网络上如果没有HTML文本格式层、CSS样式层、JavaScript执行层和图像渲染层，咋看
起来会有点儿吓人，浏览器为我们做了这些。接下来我们将不通过浏览器的帮助来格式化和理
解数据。

    python3 scrapetest.py
    它只能读取单个HTML文件
    urllib是python的标准库


BeautifulSoup简介

    它通过定位HTML标签来格式化和组织复杂的网络信息，用简单易用的Python对象为我们展
现XML结构信息。

    安装：sudo apt-get install python-bs4
    from bs4 import BeautulSoup